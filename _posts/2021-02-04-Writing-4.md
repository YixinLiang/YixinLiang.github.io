---
layout: post
title: "Writing 4"
date: 2021-02-04
---

<p>STA303 Polished Writing 2
<p>Prompt: Explain the concept of Maximum Likelihood Estimation in a casual conversation.


<p>Yeah, I think I can explain this concept to you during this waiting time. Maximum likelihood estimation is an essential statistical concept, and you will use it multiple times in your future classes. 

<p>Firstly, you need to know when you apply the maximum likelihood estimation. Typically, suppose you are given a set of observations from an unknown population. In that case, you can use this estimation method to make inferences so that the given sample will most likely be generated. Additionally, you also need to remember two essential assumptions that the data need to be independently and identically distributed. 

<p>Next, clarify the definition of parameters will build a base to understand this concept. Each model is defined by a set of parameters, and people can give particular value to them. Maximum likelihood estimation aims at estimating the parameters of a probability distribution by maximizing the likelihood function. Ok. I know you are even more confused. I will use an example to help you to understand. 

<p>For example, we want to measure the amount of time until an earthquake occurs. Then exponential distribution can describe this case. I hope you still remember it. Lambda is the parameter. Maximum likelihood estimation is trying to estimate a most likely lambda that fits our data. Now, you look like you have understood the meaning.

<p>Then, we can start to calculate it step by step. Firstly, if the data set contains n observations, you need to get the likelihood function by multiplying n density functions, given previous assumptions are satisfied. Secondly, you can log the likelihood function to ease the derivative calculations because a natural logarithm is a monotonic function. Thirdly, you need to find the estimated parameter that maximizes the log of the likelihood function by taking the derivative with respect to the parameter. Fourthly, it is better to check your results by the second derivative. If the second derivative is less than zero, then the result is the maximum likelihood estimation of the parameter.

<p>In sum, the purpose of finding the maximum likelihood estimation is solving an estimated parameter for the distribution that mostly fits the given sample. As we talked about before, there are four main steps and you need to start with calculating the likelihood function. I hope my explanation is helpful for your understanding. If you have more questions, feel free to come to my office hours.
